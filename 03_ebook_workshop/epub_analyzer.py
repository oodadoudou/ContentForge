import os
import sys
import zipfile
import xml.etree.ElementTree as ET
import html
import argparse
import tempfile
import shutil
from datetime import datetime
from pathlib import Path
import logging
import glob

# --- æ—¥å¿—è®¾ç½® ---
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

class EpubAnalyzer:
    """ä¸€ä¸ªç”¨äºå…¨é¢åˆ†æ EPUB æ–‡ä»¶å¹¶è¿”å›ç»“æ„åŒ–æ•°æ®çš„å·¥å…·ã€‚"""

    def __init__(self, epub_path):
        if not Path(epub_path).exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {epub_path}")
        self.epub_path = Path(epub_path)
        self.temp_dir = Path(tempfile.mkdtemp(prefix="epub_analyzer_"))
        self.ns = {
            'cn': 'urn:oasis:names:tc:opendocument:xmlns:container',
            'opf': 'http://www.idpf.org/2007/opf',
            'dc': 'http://purl.org/dc/elements/1.1/',
            'ncx': 'http://www.daisy.org/z3986/2005/ncx/'
        }

    def analyze(self) -> dict:
        """
        æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹å¹¶è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸ã€‚
        """
        analysis_data = {'epub_filename': self.epub_path.name}
        try:
            self._extract_epub()
            opf_path = self._find_opf_path()
            analysis_data['opf_path'] = opf_path.relative_to(self.temp_dir)
            
            self._parse_opf(opf_path, analysis_data)
            
            ncx_item = analysis_data['manifest'].get(analysis_data.get('spine_toc_id'))
            # **ä¿®å¤**: ä½¿ç”¨ opf_path.parent ä½œä¸ºåŸºå‡†æ¥æ„å»º NCX æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
            if ncx_item and ncx_item['exists']:
                full_ncx_path = opf_path.parent / ncx_item['href']
                analysis_data['toc'] = self._parse_ncx(full_ncx_path)
            else:
                analysis_data['toc'] = []

            analysis_data['file_tree'] = self._get_file_tree()
            return analysis_data

        finally:
            shutil.rmtree(self.temp_dir)
            logger.info(f"ä¸´æ—¶ç›®å½• {self.temp_dir} å·²ä¸º '{self.epub_path.name}' æ¸…ç†ã€‚")

    def _extract_epub(self):
        """è§£å‹ EPUB æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•ã€‚"""
        with zipfile.ZipFile(self.epub_path, 'r') as zf:
            zf.extractall(self.temp_dir)
        logger.info(f"EPUB '{self.epub_path.name}' å·²è§£å‹åˆ°: {self.temp_dir}")

    def _find_opf_path(self) -> Path:
        """è§£æ container.xml æ‰¾åˆ° .opf æ–‡ä»¶çš„è·¯å¾„ã€‚"""
        container_path = self.temp_dir / 'META-INF' / 'container.xml'
        if not container_path.exists():
            raise FileNotFoundError("META-INF/container.xml æœªæ‰¾åˆ°ã€‚")
        
        tree = ET.parse(container_path)
        rootfile = tree.find('.//cn:rootfile', self.ns)
        if rootfile is None or not rootfile.get('full-path'):
            raise ValueError("åœ¨ container.xml ä¸­æ— æ³•æ‰¾åˆ° rootfileã€‚")
        
        return self.temp_dir / rootfile.get('full-path')

    def _parse_opf(self, opf_path: Path, analysis_data: dict):
        """è§£æ OPF æ–‡ä»¶ã€‚"""
        tree = ET.parse(opf_path)
        
        # Metadata
        metadata = {}
        for elem in tree.findall('.//dc:*', self.ns):
            tag = elem.tag.split('}')[-1]
            metadata[f"dc:{tag}"] = elem.text if elem.text else ""
        analysis_data['metadata'] = metadata

        # Manifest
        manifest = {}
        opf_dir = opf_path.parent
        for item in tree.findall('.//opf:item', self.ns):
            item_id = item.get('id')
            href = item.get('href', '')
            media_type = item.get('media-type', '')
            file_path = opf_dir / href
            manifest[item_id] = {
                'href': href,
                'media_type': media_type,
                'exists': file_path.exists()
            }
        analysis_data['manifest'] = manifest

        # Spine
        spine = []
        spine_node = tree.find('.//opf:spine', self.ns)
        analysis_data['spine_toc_id'] = spine_node.get('toc') if spine_node is not None else None
        for itemref in spine_node.findall('.//opf:itemref', self.ns):
            spine.append(itemref.get('idref'))
        analysis_data['spine'] = spine

    def _parse_ncx(self, ncx_path: Path) -> list:
        """è§£æ NCX æ–‡ä»¶ä»¥è·å–ç›®å½•ç»“æ„ï¼Œè¿”å›å­—å…¸åˆ—è¡¨ã€‚"""
        def parse_navpoint(element):
            nav_label = element.find('ncx:navLabel/ncx:text', self.ns)
            content = element.find('ncx:content', self.ns)
            
            point_data = {
                'text': nav_label.text if nav_label is not None else "æ— æ ‡é¢˜",
                'src': content.get('src', '#') if content is not None else '#',
                'children': []
            }

            sub_points = element.findall('ncx:navPoint', self.ns)
            for sub_point in sub_points:
                point_data['children'].append(parse_navpoint(sub_point))
            return point_data

        tree = ET.parse(ncx_path)
        nav_map = tree.find('.//ncx:navMap', self.ns)
        toc_data = []
        if nav_map is not None:
            for nav_point in nav_map.findall('ncx:navPoint', self.ns):
                toc_data.append(parse_navpoint(nav_point))
        return toc_data

    def _get_file_tree(self) -> list:
        """ç”Ÿæˆç‰©ç†æ–‡ä»¶ç»“æ„çš„åˆ—è¡¨ã€‚"""
        def build_tree(dir_path: Path):
            tree_list = []
            items = sorted(list(dir_path.iterdir()), key=lambda p: (p.is_file(), p.name.lower()))
            for item in items:
                if item.is_dir():
                    tree_list.append({'name': item.name, 'type': 'folder', 'children': build_tree(item)})
                else:
                    tree_list.append({'name': item.name, 'type': 'file'})
            return tree_list
        return build_tree(self.temp_dir)

def generate_markdown_report(all_analysis_data: list, output_path: Path):
    """æ ¹æ®åˆ†ææ•°æ®åˆ—è¡¨ç”Ÿæˆä¸€ä¸ªç»Ÿä¸€çš„ Markdown æŠ¥å‘Šã€‚"""
    md = f"# EPUB åˆ†ææŠ¥å‘Š\n\n"
    md += f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    md += f"æœ¬æ¬¡å…±åˆ†æäº† **{len(all_analysis_data)}** ä¸ª EPUB æ–‡ä»¶ã€‚\n\n"

    for data in all_analysis_data:
        md += f"---\n\n"
        md += f"## ğŸ“– æ–‡ä»¶å: `{data['epub_filename']}`\n\n"

        # Metadata
        md += "### ä¸€ã€å…ƒæ•°æ® (Metadata)\n\n"
        md += "| é¡¹ç›® | å†…å®¹ |\n"
        md += "| :--- | :--- |\n"
        for k, v in data.get('metadata', {}).items():
            md += f"| `{k}` | {v} |\n"
        md += "\n"

        # Manifest
        md += "### äºŒã€æ–‡ä»¶æ¸…å• (Manifest)\n\n"
        md += "| ID | è·¯å¾„ (href) | åª’ä½“ç±»å‹ | æ–‡ä»¶çŠ¶æ€ |\n"
        md += "| :--- | :--- | :--- | :--- |\n"
        for item_id, info in data.get('manifest', {}).items():
            status = "âœ… å­˜åœ¨" if info['exists'] else "âŒ **ç¼ºå¤±**"
            md += f"| `{item_id}` | `{info['href']}` | `{info['media_type']}` | {status} |\n"
        md += "\n"

        # Spine
        md += "### ä¸‰ã€é˜…è¯»é¡ºåº (Spine)\n\n"
        for i, idref in enumerate(data.get('spine', [])):
            href = data.get('manifest', {}).get(idref, {}).get('href', 'æœªçŸ¥')
            md += f"{i+1}. `{idref}` -> `{href}`\n"
        md += "\n"

        # TOC
        md += "### å››ã€ç›®å½•ç»“æ„ (Table of Contents - NCX)\n\n"
        def format_toc(toc_list, level=0):
            toc_md = ""
            for item in toc_list:
                indent = "  " * level
                src_file, _, src_anchor = item['src'].partition('#')
                anchor_part = f" -> `#{src_anchor}`" if src_anchor else ""
                toc_md += f"{indent}- {item['text']} (`{src_file}`{anchor_part})\n"
                if item['children']:
                    toc_md += format_toc(item['children'], level + 1)
            return toc_md
        toc_content = format_toc(data.get('toc', []))
        md += toc_content if toc_content else "æœªæ‰¾åˆ°æˆ–æ— æ³•è§£æç›®å½•ã€‚\n"
        md += "\n"

        # File Tree
        md += "### äº”ã€ç‰©ç†æ–‡ä»¶ç»“æ„\n\n"
        def format_tree(tree_list, level=0):
            tree_md = ""
            for item in tree_list:
                indent = "  " * level
                icon = "ğŸ“" if item['type'] == 'folder' else "ğŸ“„"
                tree_md += f"{indent}- {icon} `{item['name']}`\n"
                if 'children' in item:
                    tree_md += format_tree(item['children'], level + 1)
            return tree_md
        md += "```\n"
        md += format_tree(data.get('file_tree', []))
        md += "```\n\n"

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(md)
    print(f"\nâœ… åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")

def main():
    """è„šæœ¬ä¸»å…¥å£ã€‚"""
    parser = argparse.ArgumentParser(description="åˆ†ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ EPUB æ–‡ä»¶å¹¶ç”Ÿæˆä¸€ä»½ç»Ÿä¸€çš„ Markdown æŠ¥å‘Šã€‚")
    parser.add_argument("target_dir", nargs='?', default='', help="åŒ…å« EPUB æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ (å¯é€‰)ã€‚")
    
    args = parser.parse_args()
    target_dir_str = args.target_dir

    if not target_dir_str:
        # **ä¿®å¤**: è®¾ç½®ç”¨æˆ·æŒ‡å®šçš„é»˜è®¤è·¯å¾„
        default_path = "/Users/doudouda/Downloads/2/"
        prompt = f"è¯·è¾“å…¥è¦åˆ†æçš„æ–‡ä»¶å¤¹è·¯å¾„ (ç›´æ¥æŒ‰ Enter é”®å°†ä½¿ç”¨: {default_path}): "
        target_dir_str = input(prompt).strip()
        if not target_dir_str:
            target_dir_str = default_path

    target_path = Path(target_dir_str)
    if not target_path.is_dir():
        print(f"é”™è¯¯: è·¯å¾„ '{target_path}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡ä»¶å¤¹ã€‚", file=sys.stderr)
        sys.exit(1)

    epub_files = glob.glob(os.path.join(target_dir_str, '*.epub'))
    if not epub_files:
        print(f"åœ¨ '{target_dir_str}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .epub æ–‡ä»¶ã€‚")
        sys.exit(0)
    
    print(f"[*] åœ¨ç›®å½•ä¸­å‘ç° {len(epub_files)} ä¸ª EPUB æ–‡ä»¶ï¼Œå¼€å§‹åˆ†æ...")
    
    all_analysis_data = []
    for epub_file in epub_files:
        try:
            print(f"  -> æ­£åœ¨åˆ†æ: {os.path.basename(epub_file)}")
            analyzer = EpubAnalyzer(epub_file)
            analysis_data = analyzer.analyze()
            all_analysis_data.append(analysis_data)
        except Exception as e:
            print(f"    âŒ åˆ†ææ–‡ä»¶ '{os.path.basename(epub_file)}' æ—¶å‡ºé”™: {e}")
            logger.error(f"åˆ†ææ–‡ä»¶ '{epub_file}' æ—¶å‡ºé”™ã€‚", exc_info=True)
    
    if all_analysis_data:
        report_path = target_path / "_EPUB_Analysis_Report.md"
        generate_markdown_report(all_analysis_data, report_path)

if __name__ == '__main__':
    main()
